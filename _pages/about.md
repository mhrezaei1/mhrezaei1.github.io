---
layout: about
title: about
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    Email: mhrezaei@arizona.edu

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am a final-year undergraduate student at the [**University of Arizona**](https://www.arizona.edu/) <img src="assets/img/uofa.png" alt="UArizona" height="20px"/> majoring in [*Computer Science*](https://www.cs.arizona.edu/) with a 4.0 GPA. I am a member of the [*Computational Language Understanding (CLU) Lab*](https://clulab.org/), advised by [Eduardo Blanco](https://eduardoblanco.github.io/), where I worked on making SLMs more robust against negation by [further pre-training](https://aclanthology.org/2025.naacl-long.413) and [paraphrasing in affirmative terms](https://aclanthology.org/2024.acl-short.55/).

Previously, I was a research intern at [**Stanford University**](https://www.stanford.edu/) <img src="assets/img/stanford.png" alt="Stanford" height="20px"/> in the [*SALT Lab*](https://saltlab.stanford.edu/) advised by [Diyi Yang](https://cs.stanford.edu/~diyiy/). There, I co-created [EgoNormia](https://egonormia.org), a benchmark for evaluating physical-social norm understanding in vision-language models.

In summer 2025, I was a post-training research intern at [**Scale AI**](https://scale.com/) <img src="assets/img/scale_logo.jpg" alt="Scale AI" height="20px"/>, where I worked on [OnlineRubrics](https://arxiv.org/abs/2510.07284), an approach for post-training LLMs with evolving rubrics to improve alignment in tasks without verifiable ground-truth.  