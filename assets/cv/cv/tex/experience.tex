\section{Experience}
\cventry{May 2025 - Present}{\href{https://scale.com}{Scale AI}}{Research Intern, Post-training}{}{}{}



\cventry{Mar. 2023 - Present}{University of Arizona - Computational Language Understanding (CLU) Lab}{Undergraduate Research Assistant}{}{}{Advisors: \href{https://eduardoblanco.github.io}{Dr. Eduardo Blanco}, \href{https://bethard.github.io/}{Dr. Steven Bethard}
\begin{itemize}
\item Research Projects:
\begin{itemize}
    \item Using Negated Commonsense Knowledge to Improve Negation Understanding (Under Review)
    \item Further Pre-training Language Models for Negation Understanding (NAACL 2025 - First Author)
    \item Affirmative Interpretations and Negation Understanding (ACL 2024 - First Author)
    \item Machine Generated Text Detection (SemEval 2024 - First Author)
    \item Hallucination Detection in Language Models (SemEval 2024)
    \item Interpreting Indirect QAs in Multiple Languages (EMNLP Findings 2024)
    \item Aggregating Crowdsourced Forecasts using LSTMs and Transformers (preprint)
\end{itemize}
\end{itemize}}

\cventry{June 2024 - Mar. 2025}{Stanford NLP Group}{Undergraduate Visiting Research Intern}{}{}{Advisor: \href{https://cs.stanford.edu/~diyiy/}{Dr. Diyi Yang}
\begin{itemize}
\item Mentors: \href{https://calebziems.com}{Caleb Ziems} and \href{https://www.zhuhao.me/}{Hao Zhu}
\item Researched on physical social norms understanding in language models (ACL 2025 (Findings) - Equal Contributor)
\item Created \href{https://egonormia.org}{EgoNormia}, a challenging benchmark for evaluating physical social norms understanding in multimodal language models
\item Part of the \href{https://www.cs.stanford.edu/research-impact}{Stanford LINXS Summer Research Program}
\end{itemize}}

\cventry{July 2023 - July 2023}{\href{https://diversity.cis.cornell.edu/programs/sonic/}{Cornell University - SoNIC Summer Research Workshop}}{Scholar}{}{}{
    Advisor: \href{https://sites.google.com/site/tapomayukh}{Dr. Tapomayukh Bhattacharjee}
\begin{itemize}
\item Worked in groups on building a smart assistive cane for individuals with visual impairments
\item Implemented perception, motion planning, and control for the robot
\item Ranked 2nd in individual final test among 40 participants
\end{itemize}}